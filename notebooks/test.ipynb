{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[<torch.utils.data.dataset.Subset object at 0x1066ddc70>, <torch.utils.data.dataset.Subset object at 0x1067bb5e0>, <torch.utils.data.dataset.Subset object at 0x1064ff040>, <torch.utils.data.dataset.Subset object at 0x106721790>, <torch.utils.data.dataset.Subset object at 0x1068a4100>]\n",
      "[10000, 9000, 8000, 7000, 6000, 10000]\n",
      "[10000, 9000, 8000, 7000, 6000]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "STATS = ((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
    "\n",
    "cifar10_train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.RandomCrop(32, padding=4, padding_mode=\"reflect\", fill=0),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*STATS, inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\"../data/raw/\", train=True,transform=cifar10_train_transform, download=True)\n",
    "\n",
    "train_size_per_client = len(trainset) // 5\n",
    "\n",
    "length_arr = [train_size_per_client] * (5 - 1)\n",
    "length_arr.append(len(trainset) - sum(length_arr))\n",
    "\n",
    "split_dataset_arr = random_split(trainset, length_arr)\n",
    "\n",
    "print(split_dataset_arr)\n",
    "\n",
    "split_length_arr = []\n",
    "for i in range(0, 5):\n",
    "    rest_size = int((1 - 0.1 * i) * len(split_dataset_arr[i]))\n",
    "    split_length_arr.append(rest_size)\n",
    "split_length_arr.append(len(trainset) - sum(split_length_arr))\n",
    "\n",
    "print(split_length_arr)\n",
    "\n",
    "split_dataset_arr = random_split(trainset, split_length_arr)\n",
    "\n",
    "print(split_length_arr[:-1])\n",
    "\n",
    "split_dataset_arr = split_dataset_arr[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
